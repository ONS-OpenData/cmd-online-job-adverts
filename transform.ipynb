{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databaker.framework import *\n",
    "import pandas as pd\n",
    "import glob, datetime\n",
    "\n",
    "## these needed to be pointed to if not pip installed \n",
    "from databakerUtils.sparsityFunctions import SparsityFiller ##\n",
    "from api_pipeline import Multi_Upload_To_Cmd ##\n",
    "\n",
    "### file paths that may need to be changed ###\n",
    "location = 'inputs/online-jobs/*.xlsx' # location of source data\n",
    "output = 'D:/' # location of output data\n",
    "metadata_file = 'inputs/online-jobs/online-job-advert-estimates-feb-2020-index-by-category-v27.csv-metadata.json' # metadata file path\n",
    "credentials = 'florence-details.json' # path to login details\n",
    "\n",
    "file = glob.glob(location)\n",
    "assert len(file) == 1, 'More than one input file located'\n",
    "file = file[0]\n",
    "\n",
    "wanted_sheets = ['Adverts by category Feb 2020']\n",
    "tab_names = [tab.name for tab in loadxlstabs(file)]\n",
    "for sheet in wanted_sheets:\n",
    "    assert sheet in tab_names, 'Sheet \"{}\" not in spreadsheet'.format(sheet)\n",
    "\n",
    "imputed_data_marker = 'x' # used for imputed values\n",
    "\n",
    "def transform(tab_name):\n",
    "    tabs = loadxlstabs(file, [tab_name])\n",
    "    \n",
    "    data_marker = '..' # used for future weeks\n",
    "    \n",
    "    for tab in tabs:\n",
    "        # row number of start point to skip rows for read_excel\n",
    "        #start_point = tab.excel_ref('A').filter(contains_string('Date'))\n",
    "        start_point = tab.excel_ref('B').filter(contains_string('Date'))\n",
    "        start_point = tab.excel_ref('B3')\n",
    "        start_point_number = start_point.y\n",
    "        number_of_indicators = len(start_point.fill(DOWN).is_not_blank().is_not_whitespace())\n",
    "        \n",
    "        # pretty hacky..\n",
    "        # if notes at bottom of spreadsheet then rows will be removed\n",
    "        #end_of_wanted_data = tab.excel_ref('A').filter(contains_string('Imputed'))\n",
    "        end_of_wanted_data = tab.excel_ref('B').filter(contains_string('Imputed'))\n",
    "        end_of_wanted_data = end_of_wanted_data.y\n",
    "        \n",
    "        #start_of_unwanted_data = tab.excel_ref('A').filter(contains_string('Note'))\n",
    "        start_of_unwanted_data = tab.excel_ref('B').filter(contains_string('Note'))\n",
    "        start_of_unwanted_data = start_of_unwanted_data.y\n",
    "        \n",
    "        if start_of_unwanted_data > end_of_wanted_data:\n",
    "            # find number of rows that are not needed\n",
    "            #lines_to_ignore = tab.excel_ref('A').filter(contains_string('Note'))\n",
    "            lines_to_ignore = tab.excel_ref('B').filter(contains_string('Note'))\n",
    "            lines_to_ignore = len(lines_to_ignore.expand(DOWN).is_not_blank().is_not_whitespace())\n",
    "            # lines to ignore plus the number of spaces between end of data and start of notes\n",
    "            lines_to_ignore += start_of_unwanted_data - end_of_wanted_data - 1\n",
    "            # number of indicators needs modifying\n",
    "            number_of_indicators -= lines_to_ignore - 1\n",
    "            \n",
    "        else:\n",
    "            lines_to_ignore = 0\n",
    "        \n",
    "    source = pd.read_excel(file, sheet_name=tab_name, skiprows=start_point_number, \n",
    "                           skipfooter=lines_to_ignore, dtype=str)\n",
    "    \n",
    "    source = source.drop(['Unnamed: 0'], axis=1)\n",
    "    \n",
    "    # check to make sure data starts at 07/02/18\n",
    "    if source.columns[1] != datetime.datetime(2018, 2, 7, 0, 0):\n",
    "        raise Exception('''\n",
    "    First column of data starting at \"{}\" rather than \"07/02/18\"\n",
    "    Week numbers will be out of sync\n",
    "    '''.format(datetime.datetime.strftime(source.columns[1], '%d-%m-%Y')))\n",
    "    \n",
    "    source = source.rename(columns={'Unnamed: 1':'Date'})\n",
    "    df_list = []\n",
    "    week_number_start = 6 # data starts 07/02/18 -> equivalent to week 6\n",
    "    for col in source.columns:\n",
    "        if col == 'Date':\n",
    "            continue            \n",
    "        \n",
    "        df_loop = pd.DataFrame()\n",
    "        df_loop['v4_1'] = source[col]\n",
    "        df_loop['date'] = ConvertDateTime(col)\n",
    "        df_loop['week-number'] = week_number_start\n",
    "        df_loop['indicator'] = source['Date']\n",
    "        df_loop['Data Marking'] = source[col].iloc[number_of_indicators-1]\n",
    "        df_list.append(df_loop)\n",
    "        \n",
    "        week_number_start += 1\n",
    "        \n",
    "    df = pd.concat(df_list).reset_index(drop=True)\n",
    "    \n",
    "    print('List of imputed values are {}'.format(df['Data Marking'].unique()))\n",
    "    \n",
    "    df.loc[pd.isnull(df['Data Marking']), 'Data Marking'] = ''\n",
    "    df['Data Marking'] = df['Data Marking'].apply(lambda x: x.replace(' only', ''))\n",
    "    \n",
    "    df.loc[df['indicator'] == df['Data Marking'], 'Data Marking'] = imputed_data_marker\n",
    "    df['Data Marking'] = df['Data Marking'].apply(DataMarker)\n",
    "    \n",
    "    df = df[df['indicator'] != 'Imputed values']\n",
    "    \n",
    "    df['calendar-years'] = df['date'].apply(lambda x: x.split('-')[-1])\n",
    "    df['time'] = df['calendar-years']\n",
    "    \n",
    "    df['uk-only'] = 'K02000001'\n",
    "    df['geography'] = 'United Kingdom'\n",
    "    \n",
    "    df['adzuna-jobs-category'] = df['indicator'].apply(Slugize)\n",
    "    \n",
    "    # create new df for each year to correct week number\n",
    "    df_list= []\n",
    "    \n",
    "    for year in df['time'].unique():\n",
    "        \n",
    "        df_loop = df[df['time'] == year].reset_index(drop=True)\n",
    "        \n",
    "        if year in ('2018', '2019'):\n",
    "             df_loop['week-number'] = df_loop['week-number'].apply(WeekNumber)\n",
    "        \n",
    "        elif int(year)%4 == 0: # has an extra week\n",
    "            \n",
    "            df_loop['week-number'] = df_loop['week-number'].apply(WeekNumberLeapYear)\n",
    "            \n",
    "        else: # week numbers are now skewed\n",
    "            df_loop['week-number'] = df_loop['week-number'].apply(lambda x: x-1)\n",
    "            df_loop['week-number'] = df_loop['week-number'].apply(WeekNumber)\n",
    "            \n",
    "        df_loop['week'] = df_loop['week-number'].apply(WeekNumberLabel)\n",
    "        \n",
    "        df_list.append(df_loop)\n",
    "    \n",
    "    df = pd.concat(df_list)\n",
    "        \n",
    "    df = df.rename(columns={\n",
    "            'indicator':'AdzunaJobsCategory',\n",
    "            'time':'Time',\n",
    "            'geography':'Geography',\n",
    "            'week':'Week'\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    df = df[[\n",
    "            'v4_1', 'Data Marking', 'calendar-years', 'Time', 'uk-only', 'Geography',\n",
    "            'adzuna-jobs-category', 'AdzunaJobsCategory', 'week-number', 'Week'\n",
    "            ]]\n",
    "    \n",
    "    output_file = OutputName(tab_name)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    SparsityFiller(output_file, data_marker)\n",
    "\n",
    "def ConvertDateTime(value):\n",
    "    return datetime.datetime.strftime(value, '%d-%m-%Y')\n",
    "\n",
    "def DataMarker(value):\n",
    "    if value == 'All':\n",
    "        return imputed_data_marker\n",
    "    elif value == imputed_data_marker:\n",
    "        return value\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def Slugize(value):\n",
    "    new_value = value.replace(' / ', '-').replace('&', 'and').replace(' ', '-').lower()\n",
    "    return new_value\n",
    "\n",
    "def WeekNumber(value):\n",
    "    number = value % 52\n",
    "    if number == 0:\n",
    "        number = 52\n",
    "    return 'week-' + str(number)\n",
    "\n",
    "def WeekNumberLeapYear(value):\n",
    "    '''same as above but for leap years'''\n",
    "    number = (value+2) % 53\n",
    "    if number == 0:\n",
    "        number = 53\n",
    "    return 'week-' + str(number)\n",
    "\n",
    "def WeekNumberLabel(value):\n",
    "    number = int(value.split('-')[-1])\n",
    "    if number < 10:\n",
    "        return 'Week 0' + str(number)\n",
    "    else:\n",
    "        return 'Week ' + str(number)\n",
    "    \n",
    "def OutputName(tab_name):\n",
    "    # returns the correct output file name from the tab name\n",
    "    if 'feb 2020' in tab_name.lower():\n",
    "        return output + 'v4-job-advert-estimates-feb-2020-index-by-category.csv'\n",
    "    elif '2019' in tab_name.lower():\n",
    "        return output + 'v4-job-advert-estimates-2019-index-by-category.csv'\n",
    "    else:\n",
    "        raise Exception('{} is not the correct tab of data'.format(tab_name))\n",
    "        \n",
    "\n",
    "''' Run Transform'''\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # variables for upload\n",
    "    dataset_id = 'online-job-advert-estimates'\n",
    "    edition = 'feb-2020-index-by-category'\n",
    "    collection_name = 'CMD online job adverts'\n",
    "    \n",
    "    for sheet in wanted_sheets:\n",
    "        transform(sheet)\n",
    "        print(sheet, 'transform complete')\n",
    "        print('Uploading {} to CMD'.format(sheet))\n",
    "        v4 = OutputName(sheet)\n",
    "        upload_dict = {\n",
    "                dataset_id:{\n",
    "                    'v4':v4,\n",
    "                    'edition':edition,\n",
    "                    'collection_name':collection_name,\n",
    "                    'metadata_file':metadata_file\n",
    "                    }\n",
    "            }\n",
    "        Multi_Upload_To_Cmd(credentials, upload_dict)\n",
    "    print('All complete!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
